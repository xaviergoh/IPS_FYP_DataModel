{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Row Labels      0x0001      0x0002      0x0003      0x0004      0x0005  \\\n",
      "0        1,1  193.201814  189.459016  183.521739  182.930175  177.560554   \n",
      "1       1,13  179.375297  184.668258  190.644342  177.951872  178.179916   \n",
      "2        1,7  180.799097  193.402954  191.345992  177.638821  183.760234   \n",
      "3       13,1  177.000000  177.031056  177.912913  189.466667  178.398625   \n",
      "4      13,13  177.000000  177.997436  178.856643  178.914110  180.496914   \n",
      "\n",
      "       0x0006      0x0007      0x0008      0x0009      0x000A      0x000B  \\\n",
      "0  177.000000  177.369458  177.735484  177.000000  177.000000  177.000000   \n",
      "1  180.367491  178.086207  177.000000  177.003846  177.000000  177.885650   \n",
      "2  184.237251  177.333333  180.013044  178.722741  177.018182  179.716904   \n",
      "3  178.428969  192.546667  183.521964  180.256471  180.503185  187.321348   \n",
      "4  188.444444  177.009174  179.334963  195.192825  177.465201  183.170306   \n",
      "\n",
      "       0x000C  \n",
      "0  177.000000  \n",
      "1  180.515152  \n",
      "2  184.456897  \n",
      "3  179.300836  \n",
      "4  188.506849  \n",
      "y_train:  ['1,1' '1,13' '1,7' '13,1' '13,13' '13,7' '19,1' '19,13' '19,7' '7,1'\n",
      " '7,13' '7,7']\n"
     ]
    }
   ],
   "source": [
    "# Load Aggregated Signature from 12 Loc as Training Set\n",
    "trainset = pd.read_csv('./Datasets/SensorLocDS/12LocAggregated.csv')\n",
    "print(trainset.head())\n",
    "lastIndex = len(trainset)\n",
    "#dataset.iloc[rowrange, columnrange]\n",
    "ips_data = trainset.iloc[:lastIndex, 1:12]\n",
    "ips_labels = trainset.iloc[:lastIndex, :1]\n",
    "k_value = math.ceil(math.sqrt(len(ips_data)))\n",
    "X = ips_data.to_numpy()\n",
    "y = ips_labels.to_numpy()\n",
    "X_train = X\n",
    "y_train = y\n",
    "y_train = y_train.reshape(len(y_train),)\n",
    "print(\"y_train: \", y_train)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), shuffle = True,test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample to Create Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  2020-03-23 15:14:49 \t end time:  2020-03-23 15:48:51\n",
      "CODE: 1T4Z\n",
      "                   Time  ID2  RSSI Location\n",
      "0  2020-03-23 15:14:49    1   192      1,1\n",
      "1  2020-03-23 15:14:49    3   177      1,1\n",
      "2  2020-03-23 15:14:49    4   179      1,1\n",
      "3  2020-03-23 15:14:50    2   189      1,1\n",
      "4  2020-03-23 15:14:51    8   177      1,1\n",
      "5  2020-03-23 15:14:51    5   177      1,1\n",
      "6  2020-03-23 15:14:51    1   193      1,1\n",
      "7  2020-03-23 15:14:51   11   177      1,1\n",
      "8  2020-03-23 15:14:51    9   177      1,1\n",
      "9  2020-03-23 15:14:51    3   180      1,1\n",
      "10 2020-03-23 15:14:52    2   182      1,1\n",
      "11 2020-03-23 15:14:53    8   177      1,1\n",
      "12 2020-03-23 15:14:53    1   191      1,1\n",
      "13 2020-03-23 15:14:53    3   185      1,1\n",
      "14 2020-03-23 15:14:53   12   177      1,1\n",
      "height:  1021\n",
      "   1  2  3  4  5  6  7  8  9  10  11  12  Location\n",
      "0  0  0  0  0  0  0  0  0  0   0   0   0         0\n",
      "1  0  0  0  0  0  0  0  0  0   0   0   0         0\n",
      "2  0  0  0  0  0  0  0  0  0   0   0   0         0\n",
      "3  0  0  0  0  0  0  0  0  0   0   0   0         0\n",
      "4  0  0  0  0  0  0  0  0  0   0   0   0         0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare type Timedelta with type int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bc4f3571a514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdfRSSI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdfLocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleStartTime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdfTimestamp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0msensorSamplesCount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfDeviceID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#dataset.iloc[rowrange, columnrange]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/timedeltas.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timedeltas._Timedelta.__richcmp__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare type Timedelta with type int"
     ]
    }
   ],
   "source": [
    "# FIX ISSUE - QUERIED ON DIFF DATES -> MORE THAN 24 HOUR DIFFERENCE!!!!\n",
    "        \n",
    "csvfile = pd.read_csv('./Datasets/SensorLocDS/Query12LocALL.csv')\n",
    "df = pd.DataFrame(csvfile)\n",
    "# print(df.head())\n",
    "df.columns = ['Time','ID2','RSSI','Location']\n",
    "# print(df.info())\n",
    "df['Time'] = df['Time'].str.strip()\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df['Time'].date='20-03-15'\n",
    "# print(\"CODE: 1A2B\\n\", df)\n",
    "\n",
    "from datetime import timedelta\n",
    "print(\"start time: \", df['Time'].iloc[0], \"\\t\", \"end time: \", df['Time'].iloc[-1])\n",
    "timeDur = ( (df['Time'].iloc[-1] - df['Time'].iloc[0]).seconds / 2 )\n",
    "df['ID2'] = df['ID2'].astype(str)\n",
    "df['ID2'] = df['ID2'].apply(int, base=16)\n",
    "sampleStartTime = df['Time'][0] + timedelta(seconds=2)\n",
    "\n",
    "\n",
    "sortdf = df.copy()\n",
    "sortdf.sort_values(by=['ID2'], inplace=True)\n",
    "\n",
    "print(\"CODE: 1T4Z\\n\", df.head(15))\n",
    "height =int(timeDur)\n",
    "print(\"height: \", height)\n",
    "resampled = pd.DataFrame(0, index=range(2*height), columns=sortdf['ID2'].unique())\n",
    "resampled['Location'] = -1\n",
    "for columns in resampled:\n",
    "    resampled[columns] = 0\n",
    "    \n",
    "\n",
    "print(resampled.head())\n",
    "#resampled.iloc[index, column] = value;\n",
    "\n",
    "from collections import Counter\n",
    "sensorSamplesCount = Counter()\n",
    "ctr=0\n",
    "for record in df.values:\n",
    "# record[0] - timestamp, record[1] - ID2, record[2] - RSSI, record[3] - Location\n",
    "    dfTimestamp = record[0]\n",
    "    dfDeviceID = record[1]\n",
    "    dfRSSI = record[2]\n",
    "    dfLocation = record[3]\n",
    "    if (record[0] <= sampleStartTime):\n",
    "        sensorSamplesCount[dfDeviceID] += 1\n",
    "        #dataset.iloc[rowrange, columnrange]\n",
    "        resampled.iloc[ctr, dfDeviceID-1] = (resampled.iloc[ctr, dfDeviceID-1] + dfRSSI) / sensorSamplesCount[dfDeviceID] \n",
    "        resampled.iloc[ctr, -1] = dfLocation #fill location\n",
    "    else:\n",
    "        ctr=ctr+1\n",
    "        sensorSamplesCount = Counter() #reset sensor sample counts\n",
    "        sampleStartTime = dfTimestamp + timedelta(seconds=2)\n",
    "        sensorSamplesCount[dfDeviceID] += 1\n",
    "        resampled.iloc[ctr, dfDeviceID-1] = (resampled.iloc[ctr, dfDeviceID-1] + dfRSSI) / sensorSamplesCount[dfDeviceID] \n",
    "        resampled.iloc[ctr, -1] = dfLocation #fill label\n",
    "\n",
    "# lastIndex = (resampled['Location'] == 0).argmax() #find first non-valid record and record index\n",
    "\n",
    "\n",
    "writeResample = False\n",
    "if (writeResample == True):\n",
    "    resampled.to_csv('./Datasets/SensorLocDS/resampled12Loc.csv', index=False) \n",
    "    print(\"FILE WRITTEN!\")\n",
    "    \n",
    "resampled.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Date       Time      ID2  \\\n",
      "0  16/3/20   15:14:49   0x0001   \n",
      "1  16/3/20   15:14:49   0x0003   \n",
      "2  16/3/20   15:14:49   0x0004   \n",
      "3  16/3/20   15:14:50   0x0002   \n",
      "4  16/3/20   15:14:51   0x0008   \n",
      "\n",
      "                                            Raw Data  RSSI Location  \n",
      "0   0201041AFF4C0002150005000100001000800000805F9...   192      1,1  \n",
      "1   0201041AFF4C0002150005000100001000800000805F9...   177      1,1  \n",
      "2   0201041AFF4C0002150005000100001000800000805F9...   179      1,1  \n",
      "3   0201041AFF4C0002150005000100001000800000805F9...   189      1,1  \n",
      "4   0201041AFF4C0002150005000100001000800000805F9...   177      1,1  \n",
      "y_test:  []\n"
     ]
    }
   ],
   "source": [
    "testset = pd.read_csv('./Datasets/SensorLocDS/Query12LocALL.csv')\n",
    "print(testset.head())\n",
    "lastIndex = len(testset)\n",
    "#dataset.iloc[rowrange, columnrange]\n",
    "ips_data = testset.iloc[0:lastIndex, :11]\n",
    "ips_labels = testset.iloc[:lastIndex, 11:]\n",
    "X = ips_data.to_numpy()\n",
    "y = ips_labels.to_numpy()\n",
    "X_test = X\n",
    "y_test = y\n",
    "y_train = y_train.reshape(len(y_train),)\n",
    "print(\"y_test: \", y_test)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), shuffle = True,test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm - Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2\n",
    "\n",
    "#Function calculates euclidean distance between two n-dimensional data instances \n",
    "def euclideanDistance(instance1, instance2):\n",
    "    #handles if instances are lists or tuples:\n",
    "    instance1 = np.array(instance1) \n",
    "    instance2 = np.array(instance2)\n",
    "    \n",
    "    '''\n",
    "    https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html\n",
    "    uses 2-norm frobenius norm and returns euclidean distance\n",
    "    '''\n",
    "    return np.linalg.norm(instance1 - instance2) #euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm - Determining Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function finds nearest neighbours; nearest -> smallest euclidean distance\n",
    "def get_neighbors(training_set, \n",
    "                  labels, \n",
    "                  test_instance, \n",
    "                  k, \n",
    "                  distance=euclideanDistance):\n",
    "    \"\"\"\n",
    "    get_neighbors calculates a list of the k nearest neighbors\n",
    "    of an instance 'test_instance'.\n",
    "    The list neighbors contains 3-tuples with  \n",
    "    (index, dist, label)\n",
    "    where\n",
    "    index    is the index from the training_set, \n",
    "    dist     is the distance between the test_instance and the \n",
    "             instance training_set[index]\n",
    "    distance is a reference to a function used to calculate the \n",
    "             distances\n",
    "    \"\"\"\n",
    "    distances = [] #empty distance array\n",
    "    \n",
    "    #calculates euclidean distance between test_instance and ALL other instances in training_set\n",
    "    for index in range(len(training_set)):\n",
    "        dist = euclideanDistance(test_instance, training_set[index])\n",
    "        distances.append((training_set[index], dist, labels[index]))\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    neighbors = distances[:k]\n",
    "    return neighbors # The list neighbors contains 3-tuples with (index, dist, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Neighbours\n",
    "outArray = []\n",
    "for i in range(n_samples):\n",
    "    neighbors = get_neighbors(X_train, \n",
    "                              y_train, \n",
    "                              X_test[i], \n",
    "                              k_value, \n",
    "                              distance=euclideanDistance)\n",
    "#     print(i,\n",
    "#           X_test[i],\n",
    "#           y_test[i],\n",
    "#           neighbors)\n",
    "    \n",
    "    outArray.append([i,\n",
    "          X_test[i],\n",
    "          y_test[i],\n",
    "          neighbors])\n",
    "\n",
    "out_df = pd.DataFrame(outArray, columns=['i', 'X_test', 'y_test', 'neighbours'])\n",
    "out_df.head()\n",
    "# out_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#LOC: outputs for each [x,y] in label, \n",
    "#     where (x_n1, y_n1) rep x and y coord of 1st neighbour resp\n",
    "#     x_out = sum(x_n1, ... x_N) / N, where total neighbours = N\n",
    "def calcLocation(neighbours): \n",
    "    x_out = 0\n",
    "    y_out = 0\n",
    "    totalNeighbours = len(neighbours)\n",
    "    for neighbour in neighbours:\n",
    "        # handle label (str) to tuple(int, int)\n",
    "        labeltuple = neighbour[2]\n",
    "        labeltuple = tuple(map(int, labeltuple.split(',')))\n",
    "#         print(\"neighbour label: \", labeltuple)\n",
    "        x_nb = labeltuple[0]\n",
    "        y_nb = labeltuple[1]\n",
    "#         print(\"x_nb: \", x_nb)\n",
    "#         print(\"y_nb: \", y_nb)\n",
    "        x_out += x_nb\n",
    "        y_out += y_nb\n",
    "#         print(\"x_out: \", x_out)\n",
    "#         print(\"y_out: \", y_out)\n",
    "    return ((x_out/totalNeighbours) , (y_out/totalNeighbours))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NON-WEIGHTED POSITION KNN\\n\")\n",
    "for i in range(n_samples):\n",
    "    neighbors = get_neighbors(X_train, \n",
    "                              y_train, \n",
    "                              X_test[i], \n",
    "                              k_value, \n",
    "                              distance=euclideanDistance)\n",
    "    testPosTuple = tuple(map(int, y_test[i][0].split(',')))\n",
    "    print(\"test location: \", testPosTuple)\n",
    "    print(\"calculalated location: \", calcLocation(neighbors))\n",
    "    print(\"distance error: \", euclideanDistance(testPosTuple, calcLocation(neighbors)))\n",
    "    print(\"----------------------------\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function returns vote 'probability' - i.e. distribution/percentage majority vote\n",
    "def vote_prob(neighbors):\n",
    "    class_counter = Counter() # Counter object - https://docs.python.org/2/library/collections.html\n",
    "    for neighbor in neighbors:\n",
    "        class_counter[neighbor[2]] += 1 #add to count of target (class)\n",
    "        \n",
    "    # aggregates into tuples ~ zip(*iterables), \n",
    "    # Return a list of the n most common elements and their counts from the most common to the least.    \n",
    "    labels, votes = zip(*class_counter.most_common()) #returns list of sorted most common [labels], [votes]\n",
    "    #print(\"L|V: \", labels, votes)\n",
    "    #print(\"Class Counter: \", class_counter.most_common)\n",
    "    winner = class_counter.most_common(1)[0][0]       #majority label\n",
    "    votes4winner = class_counter.most_common(1)[0][1] #majority vote count\n",
    "    return winner, votes4winner/sum(votes)            #returns majority label, majority proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsKNN = pd.DataFrame(0, index=range(len(X_test)), columns=['index', 'data', 'pred_location', 'label', 'error'])\n",
    "\n",
    "indexArray = []\n",
    "dataArray = []\n",
    "locArray = []\n",
    "labelArray = []\n",
    "errorArray = []\n",
    "for i in range(len(X_test)):\n",
    "    neighbors = get_neighbors(X_train, \n",
    "                              y_train, \n",
    "                              X_test[i], \n",
    "                              k_value, \n",
    "                              distance=euclideanDistance)\n",
    "    \n",
    "    testPosTuple = tuple(map(int, y_test[i][0].split(',')))\n",
    "#     print(\"test location: \", testPosTuple)\n",
    "#     print(\"calculalated location: \", calcLocation(neighbors))\n",
    "#     print(\"distance error: \", euclideanDistance(testPosTuple, calcLocation(neighbors)))\n",
    "    \n",
    "    indexArray.append(i)\n",
    "    dataArray.append(X_test[i])\n",
    "    locArray.append(calcLocation(neighbors))\n",
    "    labelArray.append(y_test[i][0])\n",
    "    errorArray.append(euclideanDistance(testPosTuple, calcLocation(neighbors)))\n",
    "\n",
    "\n",
    "resultsKNN['index'] = indexArray\n",
    "resultsKNN['data'] = dataArray\n",
    "resultsKNN['pred_location'] = locArray\n",
    "resultsKNN['label'] = labelArray \n",
    "resultsKNN['error'] = errorArray\n",
    "\n",
    "\n",
    "resultsKNN.to_csv('./Datasets/SensorLocDS/Aggregated/KNN_LOC_AGG.csv', index=False)\n",
    "print(\"FILE WRITTEN\")\n",
    "resultsKNN.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def calcLocationRankW(neighbours): \n",
    "    x_out = 0\n",
    "    y_out = 0\n",
    "    rank = 0\n",
    "    for neighbour in neighbours:\n",
    "        rank += 1\n",
    "        # handle label (str) to tuple(int, int)\n",
    "        labeltuple = neighbour[2]\n",
    "        labeltuple = tuple(map(int, labeltuple.split(',')))\n",
    "#         print(\"neighbour label: \", labeltuple)\n",
    "        x_nb = labeltuple[0]\n",
    "        y_nb = labeltuple[1]\n",
    "#         print(\"x_nb: \", x_nb)\n",
    "#         print(\"y_nb: \", y_nb)\n",
    "        x_out += x_nb*(1/rank)\n",
    "        y_out += y_nb*(1/rank)\n",
    "#         print(\"x_out: \", x_out)\n",
    "#         print(\"y_out: \", y_out)\n",
    "    return ((x_out) , (y_out))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resultsRWKNN = pd.DataFrame(0, index=range(len(X_test)), columns=['index', 'data', 'label', 'vote_result', 'prediction'])\n",
    "\n",
    "indexArray = []\n",
    "dataArray = []\n",
    "labelArray = []\n",
    "voteArray = []\n",
    "predArray = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    neighbors = get_neighbors(X_train, \n",
    "                              y_train, \n",
    "                              X_test[i], \n",
    "                              k_value, \n",
    "                              distance=euclideanDistance)\n",
    "    \n",
    "    testPosTuple = tuple(map(int, y_test[i][0].split(',')))\n",
    "    print(\"test location: \", testPosTuple)\n",
    "    print(\"calculalated location: \", calcLocationRankW(neighbors))\n",
    "    print(\"distance error: \", euclideanDistance(testPosTuple, calcLocation(neighbors)))\n",
    "    \n",
    "# resultsRWKNN['index'] = indexArray\n",
    "# resultsRWKNN['data'] = dataArray\n",
    "# resultsRWKNN['label'] = labelArray\n",
    "# resultsRWKNN['vote_result'] = voteArray\n",
    "# resultsRWKNN['prediction'] = predArray\n",
    "\n",
    "\n",
    "# resultsRWKNN.to_csv('./Datasets/Testing/RANKKNN_LOC.csv', index=False) \n",
    "# print(\"FILE WRITTEN\")\n",
    "# resultsRWKNN\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcLocationDistW(neighbours): \n",
    "    x_out = 0\n",
    "    y_out = 0\n",
    "    total_dist = 0\n",
    "    for neighbour in neighbours:\n",
    "        # handle label (str) to tuple(int, int)\n",
    "        labeltuple = neighbour[2]\n",
    "        labeltuple = tuple(map(int, labeltuple.split(',')))\n",
    "        # distance\n",
    "        dist_nb = neighbour[1]\n",
    "        total_dist += dist_nb\n",
    "#         print(\"Neighbour distance: \", dist_nb)\n",
    "#         print(\"Total distance: \", total_dist)\n",
    "        x_nb = labeltuple[0]\n",
    "        y_nb = labeltuple[1]\n",
    "#         print(\"x_nb: \", x_nb)\n",
    "#         print(\"y_nb: \", y_nb)\n",
    "        x_out += x_nb*(dist_nb)\n",
    "        y_out += y_nb*(dist_nb)\n",
    "#         print(\"x_out: \", x_out)\n",
    "#         print(\"y_out: \", y_out)\n",
    "    return ((x_out/total_dist) , (y_out/total_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "    neighbors = get_neighbors(X_train, \n",
    "                              y_train, \n",
    "                              X_test[i], \n",
    "                              k_value, \n",
    "                              distance=euclideanDistance)\n",
    "    \n",
    "    testPosTuple = tuple(map(int, y_test[i][0].split(',')))\n",
    "    print(\"test location: \", testPosTuple)\n",
    "    print(\"calculalated location: \", calcLocationDistW(neighbors))\n",
    "    print(\"distance error: \", euclideanDistance(testPosTuple, calcLocationDistW(neighbors)))\n",
    "    print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDWKNN = pd.DataFrame(0, index=range(len(X_test)), columns=['index', 'data', 'pred_location', 'label', 'error'])\n",
    "\n",
    "writeFile = True\n",
    "indexArray = []\n",
    "dataArray = []\n",
    "locArray = []\n",
    "labelArray = []\n",
    "errorArray = []\n",
    "for i in range(len(X_test)):\n",
    "    neighbors = get_neighbors(X_train, \n",
    "                              y_train, \n",
    "                              X_test[i], \n",
    "                              k_value, \n",
    "                              distance=euclideanDistance)\n",
    "    \n",
    "    testPosTuple = tuple(map(int, y_test[i][0].split(',')))\n",
    "#     print(\"test location: \", testPosTuple)\n",
    "#     print(\"calculalated location: \", calcLocationDistW(neighbors))\n",
    "#     print(\"distance error: \", euclideanDistance(testPosTuple, calcLocationDistW(neighbors)))\n",
    "    \n",
    "    indexArray.append(i)\n",
    "    dataArray.append(X_test[i])\n",
    "    locArray.append(calcLocationDistW(neighbors))\n",
    "    labelArray.append(y_test[i][0])\n",
    "    errorArray.append(euclideanDistance(testPosTuple, calcLocationDistW(neighbors)))\n",
    "\n",
    "\n",
    "resultsDWKNN['index'] = indexArray\n",
    "resultsDWKNN['data'] = dataArray\n",
    "resultsDWKNN['pred_location'] = locArray\n",
    "resultsDWKNN['label'] = labelArray \n",
    "resultsDWKNN['error'] = errorArray\n",
    "\n",
    "if (writeFile == True):\n",
    "    resultsDWKNN.to_csv('./Datasets/SensorLocDS/Aggregated/DWKNN_LOC_AGG.csv', index=False)\n",
    "    print(\"FILE WRITTEN\")\n",
    "    \n",
    "resultsDWKNN.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDWKNN = pd.read_csv('./Datasets/SensorLocDS/Aggregated/DWKNN_LOC_AGG.csv')\n",
    "# Find the unique values\n",
    "\n",
    "# unique_values = np.sort(pd.Series)\n",
    "# Make the rank array for these sorted and unique values in the dataset -\n",
    "# ranks = np.arange(0,len(unique_values))/(len(unique_values)-1)\n",
    "# Plot unique_values vs ranks\n",
    "\n",
    "error = DataDWKNN['error']\n",
    "## sort the unique values using pandas unique function\n",
    "dwknn_error = np.sort(error.unique())\n",
    "dwknn_cdf = np.arange(0,len(dwknn_error),step=1)/(len(dwknn_error)-1)\n",
    "\n",
    "## plotting    \n",
    "plt.plot(dwknn_error,dwknn_cdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataKNN = pd.read_csv('./Datasets/SensorLocDS/Aggregated/KNN_LOC_AGG.csv')\n",
    "# Find the unique values\n",
    "\n",
    "# unique_values = np.sort(pd.Series)\n",
    "# Make the rank array for these sorted and unique values in the dataset -\n",
    "# ranks = np.arange(0,len(unique_values))/(len(unique_values)-1)\n",
    "# Plot unique_values vs ranks\n",
    "\n",
    "error = DataKNN['error']\n",
    "## sort the unique values using pandas unique function\n",
    "knn_error = np.sort(error.unique())\n",
    "knn_cdf = np.arange(0,len(knn_error),step=1)/(len(knn_error)-1)\n",
    "\n",
    "## plotting    \n",
    "plt.plot(knn_error,knn_cdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDWKNN = pd.read_csv('./Datasets/SensorLocDS/Aggregated/DWKNN_LOC_AGG.csv')\n",
    "# Find the unique values\n",
    "\n",
    "# unique_values = np.sort(pd.Series)\n",
    "# Make the rank array for these sorted and unique values in the dataset -\n",
    "# ranks = np.arange(0,len(unique_values))/(len(unique_values)-1)\n",
    "# Plot unique_values vs ranks\n",
    "\n",
    "error = DataDWKNN['error']\n",
    "## sort the unique values using pandas unique function\n",
    "dwknn_error = np.sort(error.unique())\n",
    "cdf = np.arange(0,len(dwknn_error),step=1)/(len(dwknn_error)-1)\n",
    "\n",
    "## plotting    \n",
    "plt.plot(dwknn_error,cdf, \"blue\")\n",
    "\n",
    "\n",
    "DataKNN = pd.read_csv('./Datasets/SensorLocDS/Aggregated/KNN_LOC_AGG.csv')\n",
    "# Find the unique values\n",
    "\n",
    "# unique_values = np.sort(pd.Series)\n",
    "# Make the rank array for these sorted and unique values in the dataset -\n",
    "# ranks = np.arange(0,len(unique_values))/(len(unique_values)-1)\n",
    "# Plot unique_values vs ranks\n",
    "\n",
    "error = DataKNN['error']\n",
    "## sort the unique values using pandas unique function\n",
    "knn_error = np.sort(error.unique())\n",
    "cdf = np.arange(0,len(knn_error),step=1)/(len(knn_error)-1)\n",
    "\n",
    "## plotting    \n",
    "plt.plot(knn_error,cdf, \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 2*math.pi, 400)\n",
    "a = np.sin(t)\n",
    "b = np.cos(t)\n",
    "c = a + b\n",
    "\n",
    "plt.plot(t, a, 'r') # plotting t, a separately \n",
    "plt.plot(t, b, 'b') # plotting t, b separately \n",
    "plt.plot(t, c, 'g') # plotting t, c separately \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
